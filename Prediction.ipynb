{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833e052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import *\n",
    "from sklearn import model_selection, metrics, dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be419be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c9df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./data/pickle\", 'rb') as f:\n",
    "    data_X, data_Y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b7e976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 pour les données sans star, 1 pour energystar\n",
    "data_X = data_X[0]\n",
    "data_Y = data_Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ef0650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DataYear',\n",
       " 'BuildingType',\n",
       " 'ZipCode',\n",
       " 'CouncilDistrictCode',\n",
       " 'Neighborhood',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'YearBuilt',\n",
       " 'NumberofBuildings',\n",
       " 'NumberofFloors',\n",
       " 'PropertyGFATotal',\n",
       " 'PropertyGFAParking',\n",
       " 'PropertyGFABuilding(s)',\n",
       " 'LargestPropertyUseType',\n",
       " 'LargestPropertyUseTypeGFA',\n",
       " 'SecondLargestPropertyUseType',\n",
       " 'SecondLargestPropertyUseTypeGFA',\n",
       " 'ThirdLargestPropertyUseType',\n",
       " 'ThirdLargestPropertyUseTypeGFA',\n",
       " 'Steam',\n",
       " 'Electricity',\n",
       " 'Gas',\n",
       " 'SimpleAddress']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_num = list(data_X.select_dtypes(include=['float', 'int']).columns)\n",
    "col_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1807bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(data_X[col_num], data_Y['Energy'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d5e1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8f79a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29601fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  -0.035290600150939766\n",
      "R2 :  -0.03534169654567698\n",
      "R2 :  -0.017713026432810697\n",
      "R2 :  -0.09845145078352657\n",
      "R2 :  -0.07919785375218602\n",
      "R2 :  -0.03732071772895473\n",
      "R2 :  -0.03031603107486036\n",
      "R2 :  -0.069849477485459\n",
      "Score R2 final : 0.050435106744301766\n",
      "Score RMSE final : 240868683677696.0\n",
      "Score RMSLE final : 2.2796877348829403\n"
     ]
    }
   ],
   "source": [
    "dum = dummy.DummyRegressor(strategy='median')\n",
    "\n",
    "score_final = {'R2':0, 'RMSE':0, 'RMSLE':0}\n",
    "\n",
    "for train, test in kf.split(data_X):\n",
    "    # Entraînement\n",
    "    dum.fit(data_X.iloc[train], data_Y.iloc[train])\n",
    "\n",
    "    # Prédiction sur le jeu de test\n",
    "    y_pred = dum.predict(data_X.iloc[test])\n",
    "\n",
    "    \n",
    "    y_test = data_Y.iloc[test]\n",
    "    \n",
    "    # Evaluate\n",
    "    score = metrics.r2_score(y_test, y_pred)\n",
    "    print('R2 : ', score)\n",
    "    score_final['R2'] += abs(score)\n",
    "    \n",
    "    score = metrics.mean_squared_error(y_test, y_pred, squared=True)\n",
    "    #print('RMSE : ', score)\n",
    "    score_final['RMSE'] += score\n",
    "    \n",
    "    score = metrics.mean_squared_log_error(y_test.applymap(lambda x:max(0, x)), y_pred, squared=True)\n",
    "    #print('RMSLE : ', score)\n",
    "    score_final['RMSLE'] += score\n",
    "\n",
    "for k, score in score_final.items():\n",
    "    print('Score {} final : {}'.format(k, score/kf.get_n_splits()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "483ce81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.7331001370076151\n",
      "R2 :  0.6084989500135252\n",
      "R2 :  0.2575347151181409\n",
      "R2 :  0.423074901877571\n",
      "R2 :  0.37648627901783077\n",
      "R2 :  0.5239531283448888\n",
      "R2 :  0.350539051463704\n",
      "R2 :  0.588040609575441\n",
      "Score R2 final : 0.4826534715523396\n",
      "Score RMSE final : 141224626545919.9\n",
      "Score RMSLE final : 1.1978748684065283\n"
     ]
    }
   ],
   "source": [
    "data_X_tmp = data_X[col_num]\n",
    "\n",
    "score_final = {'R2':0, 'RMSE':0, 'RMSLE':0}\n",
    "\n",
    "for train, test in kf.split(data_X_tmp):\n",
    "    regr = RandomForestRegressor(max_depth=15)\n",
    "    \n",
    "    # Entraînement\n",
    "    regr.fit(data_X_tmp.iloc[train], data_Y.iloc[train])\n",
    "\n",
    "    # Prédiction sur le jeu de test\n",
    "    y_pred = regr.predict(data_X_tmp.iloc[test])\n",
    "\n",
    "    \n",
    "    y_test = data_Y.iloc[test]\n",
    "    \n",
    "    # Evaluate\n",
    "    score = metrics.r2_score(y_test, y_pred)\n",
    "    print('R2 : ', score)\n",
    "    score_final['R2'] += abs(score)\n",
    "    \n",
    "    score = metrics.mean_squared_error(y_test, y_pred, squared=True)\n",
    "    #print('RMSE : ', score)\n",
    "    score_final['RMSE'] += score\n",
    "    \n",
    "    score = metrics.mean_squared_log_error(y_test.applymap(lambda x:max(0, x)), y_pred, squared=True)\n",
    "    #print('RMSLE : ', score)\n",
    "    score_final['RMSLE'] += score\n",
    "\n",
    "for k, score in score_final.items():\n",
    "    print('Score {} final : {}'.format(k, score/kf.get_n_splits()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "714d0512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5163307489347575"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV, MultiTaskLassoCV\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "reg = MultiTaskLassoCV(cv=5).fit(data_X[col_num], data_Y)\n",
    "reg.score(data_X[col_num], data_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc325895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.4810822919039779\n",
      "R2 :  0.37020891757759644\n",
      "R2 :  0.6438792597013104\n",
      "R2 :  0.30518423472344614\n",
      "R2 :  0.14861602379995464\n",
      "R2 :  0.4504488278814423\n",
      "R2 :  0.221334330374294\n",
      "R2 :  0.5370045738817968\n",
      "Score R2 final : 0.3947198074804773\n",
      "Score RMSE final : 76831734424031.62\n",
      "Score RMSLE final : 6.843540241248162\n"
     ]
    }
   ],
   "source": [
    "data_X_tmp = data_X[col_num]\n",
    "\n",
    "score_final = {'R2':0, 'RMSE':0, 'RMSLE':0}\n",
    "\n",
    "for train, test in kf.split(data_X_tmp):\n",
    "    regr = MultiTaskLassoCV(cv=5)\n",
    "    \n",
    "    # Entraînement\n",
    "    regr.fit(data_X_tmp.iloc[train], data_Y.iloc[train])\n",
    "\n",
    "    # Prédiction sur le jeu de test\n",
    "    y_pred = regr.predict(data_X_tmp.iloc[test])\n",
    "\n",
    "    \n",
    "    y_test = data_Y.iloc[test]\n",
    "    \n",
    "    # Evaluate\n",
    "    score = metrics.r2_score(y_test, y_pred)\n",
    "    print('R2 : ', score)\n",
    "    score_final['R2'] += abs(score)\n",
    "    \n",
    "    score = metrics.mean_squared_error(y_test, y_pred, squared=True)\n",
    "    #print('RMSE : ', score)\n",
    "    score_final['RMSE'] += score\n",
    "    \n",
    "    score = metrics.mean_squared_log_error(y_test.applymap(lambda x:max(0, x)), [[max(0, f) for f in e] for e in y_pred], squared=True)\n",
    "    #print('RMSLE : ', score)\n",
    "    score_final['RMSLE'] += score\n",
    "\n",
    "for k, score in score_final.items():\n",
    "    print('Score {} final : {}'.format(k, score/kf.get_n_splits()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f637fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search_cv_models(X, y, models, params):\n",
    "    # Initialiser la variable pour enregistrer le meilleur score\n",
    "    best_score = 0\n",
    "    # Initialiser la variable pour enregistrer le meilleur modèle\n",
    "    best_model = None\n",
    "    # Boucler à travers les modèles et les paramètres correspondants\n",
    "    for model, model_params in zip(models, params):\n",
    "        # Créer un objet GridSearchCV pour ce modèle et ces paramètres\n",
    "        gs = GridSearchCV(model, model_params, cv=5, error_score='raise', scoring='r2')\n",
    "        # Entraîner le modèle sur les données X et y\n",
    "        gs.fit(X, y)\n",
    "        print(gs.best_score_)\n",
    "        print(gs.best_estimator_)\n",
    "        # Si le meilleur score de ce modèle est supérieur au meilleur score actuel, le mettre à jour\n",
    "        if gs.best_score_ > best_score:\n",
    "            best_score = gs.best_score_\n",
    "            best_model = gs.best_estimator_\n",
    "    # Renvoyer le meilleur modèle\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e388b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3098119774009346\n",
      "LassoCV(cv=4)\n",
      "0.3122471606949108\n",
      "RandomForestRegressor(max_depth=10)\n",
      "Le meilleur modèle est: RandomForestRegressor(max_depth=10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Une liste de modèles\n",
    "models = [LassoCV(), RandomForestRegressor()]\n",
    "# Une liste de paramètres pour les modèles correspondants\n",
    "params = [{'cv':[2, 4, 5, 8, 10, 15]},\n",
    "          {\"max_depth\": [3, 5, 8, 10, 15, 20, 30, 40, 50]}]\n",
    "\n",
    "best_model = grid_search_cv_models(data_X[col_num], data_Y['CO2'], models, params)\n",
    "print(\"Le meilleur modèle est:\", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2195c917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
