{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833e052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import *\n",
    "from sklearn import model_selection, metrics, dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be419be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c9df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./data/pickle\", 'rb') as f:\n",
    "    data_X, data_Y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b7e976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 pour les données sans star, 1 pour energystar\n",
    "data_X = data_X[0]\n",
    "data_Y = data_Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ef0650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BuildingType',\n",
       " 'PrimaryPropertyType',\n",
       " 'ZipCode',\n",
       " 'CouncilDistrictCode',\n",
       " 'Neighborhood',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'YearBuilt',\n",
       " 'NumberofBuildings',\n",
       " 'NumberofFloors',\n",
       " 'PropertyGFATotal',\n",
       " 'PropertyGFAParking',\n",
       " 'PropertyGFABuilding(s)',\n",
       " 'LargestPropertyUseType',\n",
       " 'LargestPropertyUseTypeGFA',\n",
       " 'SecondLargestPropertyUseType',\n",
       " 'SecondLargestPropertyUseTypeGFA',\n",
       " 'ThirdLargestPropertyUseType',\n",
       " 'ThirdLargestPropertyUseTypeGFA',\n",
       " 'Steam',\n",
       " 'Electricity',\n",
       " 'Gas',\n",
       " 'SimpleAddress',\n",
       " 'NumberOfPropertyUseTypes',\n",
       " 'SurfaceInside',\n",
       " 'Age',\n",
       " 'EquatorProximity',\n",
       " 'SeaProximity',\n",
       " 'SeaProximityLog',\n",
       " 'SeaProximityLimit',\n",
       " 'SeaProximityLogLimit']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_num = list(data_X.select_dtypes(include=['float', 'int']).columns)\n",
    "col_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1807bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(data_X[col_num], data_Y['Energy'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d5e1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8f79a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29601fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  -0.03509961405163475\n",
      "R2 :  -0.11067168990771836\n",
      "R2 :  -0.024344143904872717\n",
      "R2 :  -0.030476916985302527\n",
      "R2 :  -0.06065029581975723\n",
      "R2 :  -0.05453289570819242\n",
      "R2 :  -0.015704315555755133\n",
      "R2 :  -0.0767006165803309\n",
      "Score R2 final : 0.051022561064195504\n",
      "Score RMSE final : 240823770284032.0\n",
      "Score RMSLE final : 2.278740158819589\n"
     ]
    }
   ],
   "source": [
    "dum = dummy.DummyRegressor(strategy='median')\n",
    "\n",
    "score_final = {'R2':0, 'RMSE':0, 'RMSLE':0}\n",
    "\n",
    "for train, test in kf.split(data_X):\n",
    "    # Entraînement\n",
    "    dum.fit(data_X.iloc[train], data_Y.iloc[train])\n",
    "\n",
    "    # Prédiction sur le jeu de test\n",
    "    y_pred = dum.predict(data_X.iloc[test])\n",
    "\n",
    "    \n",
    "    y_test = data_Y.iloc[test]\n",
    "    \n",
    "    # Evaluate\n",
    "    score = metrics.r2_score(y_test, y_pred)\n",
    "    print('R2 : ', score)\n",
    "    score_final['R2'] += abs(score)\n",
    "    \n",
    "    score = metrics.mean_squared_error(y_test, y_pred, squared=True)\n",
    "    #print('RMSE : ', score)\n",
    "    score_final['RMSE'] += score\n",
    "    \n",
    "    score = metrics.mean_squared_log_error(y_test.applymap(lambda x:max(0, x)), y_pred, squared=True)\n",
    "    #print('RMSLE : ', score)\n",
    "    score_final['RMSLE'] += score\n",
    "\n",
    "for k, score in score_final.items():\n",
    "    print('Score {} final : {}'.format(k, score/kf.get_n_splits()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "483ce81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.708803523029698\n",
      "R2 :  0.5438610556371254\n",
      "R2 :  0.25529256598593325\n",
      "R2 :  0.713867694661211\n",
      "R2 :  0.4975411864945473\n",
      "R2 :  0.33946202380404117\n",
      "R2 :  0.34450518451060363\n",
      "R2 :  0.6059530470394804\n",
      "Score R2 final : 0.50116078514533\n",
      "Score RMSE final : 145363573832897.84\n",
      "Score RMSLE final : 1.193926823244094\n"
     ]
    }
   ],
   "source": [
    "data_X_tmp = data_X[col_num]\n",
    "\n",
    "score_final = {'R2':0, 'RMSE':0, 'RMSLE':0}\n",
    "\n",
    "for train, test in kf.split(data_X_tmp):\n",
    "    regr = RandomForestRegressor(max_depth=15)\n",
    "    \n",
    "    # Entraînement\n",
    "    regr.fit(data_X_tmp.iloc[train], data_Y.iloc[train])\n",
    "\n",
    "    # Prédiction sur le jeu de test\n",
    "    y_pred = regr.predict(data_X_tmp.iloc[test])\n",
    "\n",
    "    \n",
    "    y_test = data_Y.iloc[test]\n",
    "    \n",
    "    # Evaluate\n",
    "    score = metrics.r2_score(y_test, y_pred)\n",
    "    print('R2 : ', score)\n",
    "    score_final['R2'] += abs(score)\n",
    "    \n",
    "    score = metrics.mean_squared_error(y_test, y_pred, squared=True)\n",
    "    #print('RMSE : ', score)\n",
    "    score_final['RMSE'] += score\n",
    "    \n",
    "    score = metrics.mean_squared_log_error(y_test.applymap(lambda x:max(0, x)), y_pred, squared=True)\n",
    "    #print('RMSLE : ', score)\n",
    "    score_final['RMSLE'] += score\n",
    "\n",
    "for k, score in score_final.items():\n",
    "    print('Score {} final : {}'.format(k, score/kf.get_n_splits()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "714d0512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5240912145340775"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV, MultiTaskLassoCV\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "reg = MultiTaskLassoCV(cv=5).fit(data_X[col_num], data_Y)\n",
    "reg.score(data_X[col_num], data_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc325895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.44818534226758694\n",
      "R2 :  0.4216657902196019\n",
      "R2 :  0.31717709836572927\n",
      "R2 :  0.3448347759744504\n",
      "R2 :  0.5048594186582999\n",
      "R2 :  0.38576708535762794\n",
      "R2 :  0.20711034633524955\n",
      "R2 :  0.5873648358842445\n",
      "Score R2 final : 0.4021205866328488\n",
      "Score RMSE final : 70541299470321.66\n",
      "Score RMSLE final : 5.914829956579185\n"
     ]
    }
   ],
   "source": [
    "data_X_tmp = data_X[col_num]\n",
    "\n",
    "score_final = {'R2':0, 'RMSE':0, 'RMSLE':0}\n",
    "\n",
    "for train, test in kf.split(data_X_tmp):\n",
    "    regr = MultiTaskLassoCV(cv=4)\n",
    "    \n",
    "    # Entraînement\n",
    "    regr.fit(data_X_tmp.iloc[train], data_Y.iloc[train])\n",
    "\n",
    "    # Prédiction sur le jeu de test\n",
    "    y_pred = regr.predict(data_X_tmp.iloc[test])\n",
    "\n",
    "    \n",
    "    y_test = data_Y.iloc[test]\n",
    "    \n",
    "    # Evaluate\n",
    "    score = metrics.r2_score(y_test, y_pred)\n",
    "    print('R2 : ', score)\n",
    "    score_final['R2'] += abs(score)\n",
    "    \n",
    "    score = metrics.mean_squared_error(y_test, y_pred, squared=True)\n",
    "    #print('RMSE : ', score)\n",
    "    score_final['RMSE'] += score\n",
    "    \n",
    "    score = metrics.mean_squared_log_error(y_test.applymap(lambda x:max(0, x)), [[max(0, f) for f in e] for e in y_pred], squared=True)\n",
    "    #print('RMSLE : ', score)\n",
    "    score_final['RMSLE'] += score\n",
    "\n",
    "for k, score in score_final.items():\n",
    "    print('Score {} final : {}'.format(k, score/kf.get_n_splits()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f637fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search_cv_models(X, y, models, params):\n",
    "    # Initialiser la variable pour enregistrer le meilleur score\n",
    "    best_score = 0\n",
    "    # Initialiser la variable pour enregistrer le meilleur modèle\n",
    "    best_model = None\n",
    "    # Boucler à travers les modèles et les paramètres correspondants\n",
    "    for model, model_params in zip(models, params):\n",
    "        # Créer un objet GridSearchCV pour ce modèle et ces paramètres\n",
    "        gs = GridSearchCV(model, model_params, cv=5, error_score='raise', scoring='r2')\n",
    "        # Entraîner le modèle sur les données X et y\n",
    "        gs.fit(X, y)\n",
    "        print(gs.best_score_)\n",
    "        print(gs.best_estimator_)\n",
    "        # Si le meilleur score de ce modèle est supérieur au meilleur score actuel, le mettre à jour\n",
    "        if gs.best_score_ > best_score:\n",
    "            best_score = gs.best_score_\n",
    "            best_model = gs.best_estimator_\n",
    "    # Renvoyer le meilleur modèle\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e388b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17789592681783759\n",
      "LassoCV(cv=2)\n",
      "0.36956244150180423\n",
      "RandomForestRegressor(max_depth=15)\n",
      "Le meilleur modèle est: RandomForestRegressor(max_depth=15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Une liste de modèles\n",
    "models = [LassoCV(), RandomForestRegressor()]\n",
    "# Une liste de paramètres pour les modèles correspondants\n",
    "params = [{'cv':[2, 4, 5, 8, 10, 15]},\n",
    "          {\"max_depth\": [3, 5, 8, 10, 15, 20, 30, 40, 50]}]\n",
    "\n",
    "best_model = grid_search_cv_models(data_X[col_num], data_Y['CO2'], models, params)\n",
    "print(\"Le meilleur modèle est:\", best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
